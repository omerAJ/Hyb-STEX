{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = \"NYCTaxi\"\n",
    "data_path = fr\"D:\\omer\\ST-SSL\\data\\{dataset}\\train.npz\"\n",
    "x_train = np.load(data_path)[\"x\"]\n",
    "y_train = np.load(data_path)[\"y\"]\n",
    "extreme_values_binary_tensor = np.load(data_path)[\"evs\"]\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}, evs.shape: {extreme_values_binary_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot from the gt EVs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plotting for the first node (as the loop range is 1, it plots only the first node)\n",
    "for node_index in range(1):\n",
    "    inflow = y_train[:, 0, node_index, 0]\n",
    "    outflow = y_train[:, 0, node_index, 1]\n",
    "    \n",
    "    # Extract extreme indicators for inflow and outflow\n",
    "    extreme_inflow_indicator = extreme_values_binary_tensor[:, 0, node_index, 0]\n",
    "    # extreme_outflow_indicator = extreme_values_binary_tensor[:, 0, node_index, 1]\n",
    "    \n",
    "    # Identify indices where extreme events occur\n",
    "    extreme_inflow_indices = np.where(extreme_inflow_indicator == 1)[0]\n",
    "    # extreme_outflow_indices = np.where(extreme_outflow_indicator == 1)[0]\n",
    "\n",
    "    # Plotting inflow and outflow\n",
    "    plt.subplot(1, 1, node_index + 1)\n",
    "    plt.plot(inflow, label='Inflow')\n",
    "    # plt.plot(outflow, label='Outflow')\n",
    "\n",
    "    # Marking the extreme events\n",
    "    plt.scatter(extreme_inflow_indices, inflow[extreme_inflow_indices], color='red', label='Extreme Inflow', marker='o')\n",
    "    # plt.scatter(extreme_outflow_indices, outflow[extreme_outflow_indices], color='blue', label='Extreme Outflow', marker='x')\n",
    "\n",
    "    plt.title(f'Node {node_index + 1}')\n",
    "    plt.xlabel('Time (sample index)')\n",
    "    plt.ylabel('Flow')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting evs from the learnt classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "import yaml \n",
    "import argparse\n",
    "import traceback\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from model.models import STSSL\n",
    "from model.trainer import Trainer\n",
    "from lib.dataloader import get_dataloader\n",
    "from lib.utils import (\n",
    "    init_seed,\n",
    "    get_model_params,\n",
    "    load_graph, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "\n",
    "# Define your configurations directly\n",
    "configs = {\n",
    "    'config_filename': 'configs/NYCTaxi.yaml',\n",
    "    'S_Loss': 0,\n",
    "    'T_Loss': 0,\n",
    "    'seed': 1,\n",
    "    'comment': \"testing\",\n",
    "    'cheb_order': 3,\n",
    "    'graph_init': \"8_neighbours\",\n",
    "    'self_attention_flag': True,\n",
    "    'cross_attention_flag': False,\n",
    "    'feedforward_flag': False,\n",
    "    'layer_norm_flag': False,\n",
    "    'additional_sa_flag': False,\n",
    "    'learnable_flag': False,\n",
    "    'rank': 0,\n",
    "    'pos_emb_flag': False,\n",
    "    'add_8': True,\n",
    "    'add_eye': False,\n",
    "    'add_x_encoder': False,\n",
    "    'freeze_encoder': False,\n",
    "    'ipe': 1,\n",
    "    \"mode\": \"pretrain\"\n",
    "}\n",
    "\n",
    "# Optionally print the starting experiment configurations\n",
    "print(f\"Starting experiment with configurations in {configs['config_filename']}...\")\n",
    "\n",
    "# Simulate a brief pause\n",
    "time.sleep(3)\n",
    "\n",
    "# Load configurations from a file (if necessary, or you could just use the dictionary as is)\n",
    "with open(configs['config_filename'], 'r') as file:\n",
    "    file_configs = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    configs.update(file_configs)\n",
    "\n",
    "# You can add logic to modify configurations based on your conditions here\n",
    "experiment_name = \"pred_\"\n",
    "if configs['S_Loss'] == 1:\n",
    "    experiment_name += \"+S\"\n",
    "if configs['T_Loss'] == 1:\n",
    "    experiment_name += \"+T\"\n",
    "experiment_name += f\"_seed={configs['seed']}\"\n",
    "\n",
    "configs['comment'] = \"noComment\"\n",
    "configs['ipe'] = 1000\n",
    "configs['loss'] = \"mae\"\n",
    "configs['threshold_adj_mx'] = False\n",
    "configs['affinity_conv'] = False\n",
    "configs[\"experimentName\"] = experiment_name\n",
    "configs[\"mode\"] = \"test\"\n",
    "configs[\"load_path\"] = None\n",
    "\n",
    "# Print the final configuration to start the experiment\n",
    "print(f\"Starting experiment with configurations {configs}...\")\n",
    "args = argparse.Namespace(**configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed(args.seed)\n",
    "if not torch.cuda.is_available():\n",
    "    args.device = 'cuda'\n",
    "\n",
    "## load dataset\n",
    "dataloader = get_dataloader(\n",
    "    data_dir=args.data_dir, \n",
    "    dataset=args.dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    test_batch_size=args.test_batch_size,\n",
    "    scalar_type='Standard'\n",
    ")\n",
    "graph = load_graph(args.graph_file, device=args.device)\n",
    "args.num_nodes = len(graph)\n",
    "\n",
    "## init model and set optimizer\n",
    "model = STSSL(args).to(args.device)\n",
    "\n",
    "args.best_path = r'D:\\omer\\ST-SSL\\experiments\\NYCTaxi\\pred__seed=1\\20240719-155344\\evl (cheating)\\best_model.pth'\n",
    "state_dict = torch.load(\n",
    "                args.best_path,\n",
    "                map_location=torch.device(args.device)\n",
    "            )\n",
    "msg = model.load_state_dict(state_dict['model'])\n",
    "print(\"Load saved model msg: \", msg)\n",
    "\n",
    "model_parameters = get_model_params([model])\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model_parameters, \n",
    "    lr=args.lr_init, \n",
    "    eps=1.0e-8, \n",
    "    weight_decay=0, \n",
    "    amsgrad=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start training\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    dataloader=dataloader,\n",
    "    graph=graph, \n",
    "    args=args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.metrics import test_metrics\n",
    "\n",
    "\n",
    "def test(model, dataloader, scaler, graph, logger, args):\n",
    "    model.eval()\n",
    "    evs_true = []\n",
    "    evs_pred = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    bias_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target, evs) in enumerate(dataloader):\n",
    "            repr1, repr1_cls = model(data, graph)                \n",
    "            pred_output = model.predict(repr1, repr1_cls)\n",
    "            evs_predicted = model.get_evs(repr1_cls)\n",
    "            bias = model.get_bias(repr1)\n",
    "            y_true.append(target)\n",
    "            y_pred.append(pred_output)\n",
    "            evs_true.append(evs)\n",
    "            evs_pred.append(evs_predicted)\n",
    "            bias_pred.append(bias)\n",
    "\n",
    "    # y_true = torch.cat(y_true, dim=0).cpu().numpy()\n",
    "    # y_pred = torch.cat(y_pred, dim=0).cpu().numpy()\n",
    "    evs_true = torch.cat(evs_true, dim=0).cpu().numpy()\n",
    "    evs_pred = torch.cat(evs_pred, dim=0).cpu().numpy()\n",
    "    bias_pred = torch.cat(bias_pred, dim=0).cpu().numpy()\n",
    "    y_true = scaler.inverse_transform(torch.cat(y_true, dim=0)).cpu().numpy()\n",
    "    y_pred = scaler.inverse_transform(torch.cat(y_pred, dim=0)).cpu().numpy()\n",
    "    # bias_pred = scaler.inverse_transform(torch.cat(bias_pred, dim=0)).cpu().numpy()\n",
    "    mask = np.where(y_true > (5), True, False)\n",
    "    # true = true[mask]\n",
    "    # pred = pred[mask]\n",
    "    test_results = []\n",
    "    # inflow\n",
    "    mae, mape = test_metrics(y_pred[..., 0], y_true[..., 0])\n",
    "    logger.info(\"test, MAE: {:.2f}, test MAPE: {:.4f}%\".format(mae, mape*100))\n",
    "    test_results.append([mae, mape])\n",
    "    \n",
    "    print(\"y_true.shape: \", y_true.shape, \"y_pred.shape: \", y_pred.shape)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ## to plot all regions \n",
    "    # plt.plot(y_true[..., 0].flatten()[3000:4000], label='True Values')\n",
    "    # plt.plot(y_pred[..., 0].flatten()[3000:4000], label='Predictions')\n",
    "    ## to plot summed up regions\n",
    "    # plt.plot(np.sum(y_true[:, :, :, :], axis=2).flatten()\n",
    "    #         , label='True Values')\n",
    "    # plt.plot(np.sum(y_pred[:, :, :, :], axis=2).flatten(), label='Predictions')\n",
    "    mask = y_true > 5\n",
    "\n",
    "    # Apply the mask to y_true and y_pred to filter values\n",
    "    masked_y_true = np.where(mask, y_true, np.nan)  # Replace unmasked values with NaN\n",
    "    masked_y_pred = np.where(mask, y_pred, np.nan)  # Same for y_pred\n",
    "    print(\"masked_y_true.shape: \", masked_y_true.shape, \"masked_y_pred.shape: \", masked_y_pred.shape)\n",
    "    # Sum and flatten the masked values for plotting\n",
    "    # Using np.nansum to ignore NaN values in summation\n",
    "    summed_masked_y_true = np.nansum(masked_y_true, axis=2).flatten()\n",
    "    summed_masked_y_pred = np.nansum(masked_y_pred, axis=2).flatten()\n",
    "    plt.plot(summed_masked_y_true, label='True Values (Masked)', color='blue', linewidth=2, linestyle='-')\n",
    "    plt.plot(summed_masked_y_pred, label='Predictions (Masked)', color='red', linewidth=2, linestyle='--')\n",
    "    plt.title(\"Comparison of True and Predicted Values\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # outflow \n",
    "    mae, mape = test_metrics(y_pred[..., 1], y_true[..., 1])\n",
    "    logger.info(\"OUTFLOW, MAE: {:.2f}, MAPE: {:.4f}%\".format(mae, mape*100))\n",
    "    # test_results.append([mae, mape]) \n",
    "\n",
    "    return np.stack(test_results, axis=0), y_true, y_pred, evs_true, evs_pred, bias_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot from the newly defined binary tensor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_train and extreme_indicator_tensor are defined with the same shape\n",
    "# and extreme_indicator_tensor contains 1 where there's an extreme event and 0 otherwise\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plotting for the first node (as the loop range is 1, it plots only the first node)\n",
    "for node_index in range(3):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    start, end = 0, 350\n",
    "    inflow = y_true[start:end, 0, node_index, 0]\n",
    "    ## actual inflow\n",
    "    inflow_node = y_true[start:end, 0, node_index, 0]\n",
    "    plt.plot(inflow_node, label='Inflow')\n",
    "\n",
    "    ## predicted bias to add in inflow\n",
    "    bias_pred_node = bias_pred[start:end, 0, node_index, 0]\n",
    "    bias_pred_scaled = dataloader['scaler'].inverse_transform(bias_pred_node)\n",
    "    plt.plot(bias_pred_scaled, label='bias')\n",
    "\n",
    "    ## predicted bias scaled by the indicator\n",
    "    extreme_inflow_indicator = evs_pred[start:end, 0, node_index, 0]\n",
    "    bias_pred_node_scaled = bias_pred_scaled * extreme_inflow_indicator\n",
    "    plt.plot(bias_pred_node_scaled, label='bias_scaled')\n",
    "    \n",
    "    ## difference between the actual inflow and the predicted inflow\n",
    "    inflow_pred_node = y_pred[start:end, 0, node_index, 0]\n",
    "    diff = inflow_node - inflow_pred_node\n",
    "    plt.plot(inflow_pred_node, label='pred')\n",
    "\n",
    "    ## prediction - bias\n",
    "    pred_bias = inflow_pred_node - bias_pred_node_scaled\n",
    "    plt.plot(pred_bias, label='pred-bias')\n",
    "\n",
    "    extreme_inflow_indicator_true = evs_true[start:end, 0, node_index, 0]\n",
    "    bias_pred_node = bias_pred[start:end, 0, node_index, 0]\n",
    "\n",
    "    # Identify indices where extreme events occur\n",
    "    extreme_inflow_indices = np.where(extreme_inflow_indicator >= .5)[0]\n",
    "    extreme_inflow_indices_true = np.where(extreme_inflow_indicator_true == 1)[0]\n",
    "    # extreme_outflow_indices = np.where(extreme_outflow_indicator == 1)[0]\n",
    "\n",
    "    # Plotting inflow and outflow\n",
    "    \n",
    "    \n",
    "    # plt.plot(outflow, label='Outflow')\n",
    "\n",
    "    # Marking the extreme events\n",
    "    plt.scatter(extreme_inflow_indices_true, inflow[extreme_inflow_indices_true], color='green', label='Extreme Inflow _ gt', marker='o')\n",
    "    plt.scatter(extreme_inflow_indices, inflow[extreme_inflow_indices], color='red', label='Extreme Inflow _ pred', marker='x')\n",
    "    \n",
    "    # plt.scatter(extreme_outflow_indices, outflow[extreme_outflow_indices], color='blue', label='Extreme Outflow', marker='x')\n",
    "\n",
    "    plt.title(f'Node {node_index + 1}')\n",
    "    plt.xlabel('Time (sample index)')\n",
    "    plt.ylabel('Flow')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot from the newly defined binary tensor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_train and extreme_indicator_tensor are defined with the same shape\n",
    "# and extreme_indicator_tensor contains 1 where there's an extreme event and 0 otherwise\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plotting for the first node (as the loop range is 1, it plots only the first node)\n",
    "for node_index in range(1):\n",
    "    inflow = y_true[:, 0, node_index, 0]\n",
    "    # outflow = y_train[:, 0, node_index, 1]\n",
    "    \n",
    "    # Extract extreme indicators for inflow and outflow\n",
    "    extreme_inflow_indicator = evs_pred[:, 0, node_index, 0]\n",
    "    extreme_inflow_indicator_true = evs_true[:, 0, node_index, 0]\n",
    "    # print(\"extreme_inflow_indicator\", extreme_inflow_indicator)\n",
    "    # extreme_outflow_indicator = extreme_values_binary_tensor[:, 0, node_index, 1]\n",
    "    \n",
    "    # Identify indices where extreme events occur\n",
    "    extreme_inflow_indices = np.where(extreme_inflow_indicator >= .2)[0]\n",
    "    extreme_inflow_indices_true = np.where(extreme_inflow_indicator_true == 1)[0]\n",
    "    # extreme_outflow_indices = np.where(extreme_outflow_indicator == 1)[0]\n",
    "\n",
    "    # Plotting inflow and outflow\n",
    "    plt.subplot(1, 1, node_index + 1)\n",
    "    plt.plot(inflow, label='Inflow')\n",
    "    # plt.plot(outflow, label='Outflow')\n",
    "\n",
    "    # Marking the extreme events\n",
    "    plt.scatter(extreme_inflow_indices_true, inflow[extreme_inflow_indices_true], color='green', label='Extreme Inflow _ gt', marker='o')\n",
    "    plt.scatter(extreme_inflow_indices, inflow[extreme_inflow_indices], color='red', label='Extreme Inflow _ pred', marker='x')\n",
    "    \n",
    "    # plt.scatter(extreme_outflow_indices, outflow[extreme_outflow_indices], color='blue', label='Extreme Outflow', marker='x')\n",
    "\n",
    "    plt.title(f'Node {node_index + 1}')\n",
    "    plt.xlabel('Time (sample index)')\n",
    "    plt.ylabel('Flow')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evs_true, evs_pred\n",
    "# evs_true.shape\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,\n",
    "                             balanced_accuracy_score, roc_auc_score, precision_recall_curve, auc)\n",
    "# Threshold predictions at 0.2\n",
    "evs_pred_binary = (evs_pred >= 0.25).astype(int)\n",
    "\n",
    "# Flatten the arrays to fit the metrics functions\n",
    "evs_true_flat = evs_true.flatten()\n",
    "evs_pred_flat = evs_pred_binary.flatten()\n",
    "evs_pred_probs_flat = evs_pred.flatten()  # Use raw probabilities for AUC and precision-recall calculations\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(evs_true_flat, evs_pred_flat)\n",
    "precision = precision_score(evs_true_flat, evs_pred_flat)\n",
    "recall = recall_score(evs_true_flat, evs_pred_flat)\n",
    "f1 = f1_score(evs_true_flat, evs_pred_flat)\n",
    "balanced_acc = balanced_accuracy_score(evs_true_flat, evs_pred_flat)\n",
    "roc_auc = roc_auc_score(evs_true_flat, evs_pred_probs_flat)\n",
    "\n",
    "# Precision-Recall Curve and AUC\n",
    "precision_points, recall_points, _ = precision_recall_curve(evs_true_flat, evs_pred_probs_flat)\n",
    "auc_pr = auc(recall_points, precision_points)\n",
    "\n",
    "# Display the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Precision-Recall AUC:\", auc_pr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "# Example data, replace these with your actual data\n",
    "evs_pred_binary = (evs_pred >= 0.25).astype(int)       # Threshold predictions at 0.2\n",
    "\n",
    "# Flatten the arrays\n",
    "evs_true_flat = evs_true.flatten()\n",
    "evs_pred_flat = evs_pred_binary.flatten()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(evs_true_flat, evs_pred_flat)\n",
    "\n",
    "# Plotting the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[\"Normal\", \"Extreme\"], yticklabels=[\"Normal\", \"Extreme\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0, 1, 0.05):\n",
    "    # Example data, replace these with your actual data\n",
    "    print(t)\n",
    "    evs_pred_binary = (evs_pred >= t).astype(int)       # Threshold predictions at 0.2\n",
    "\n",
    "    # Flatten the arrays\n",
    "    evs_true_flat = evs_true.flatten()\n",
    "    evs_pred_flat = evs_pred_binary.flatten()\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(evs_true_flat, evs_pred_flat)\n",
    "\n",
    "    # Plotting the confusion matrix using seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=[\"Normal\", \"Extreme\"], yticklabels=[\"Normal\", \"Extreme\"])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-SSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
