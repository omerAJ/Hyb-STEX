2024-01-24 13:39:42: Experiment log path in: D:\omer\ST-SSL\experiments\NYCBike1\20240124-133942
2024-01-24 13:39:42: Experiment configs are: Namespace(batch_size=32, best_path='None', d_input=2, d_model=64, d_output=2, data_dir='data', dataset='NYCBike1', debug=False, device='cuda', dropout=0.2, early_stop=True, early_stop_patience=15, epochs=100, grad_norm=True, graph_file='data/NYCBike1/adj_mx.npz', input_length=19, log_dir='D:\\omer\\ST-SSL\\experiments\\NYCBike1\\20240124-133942', lr_init=0.001, max_grad_norm=5, mode='train', nmb_prototype=6, num_nodes=128, percent=0.1, seed=31, shm_temp=0.5, temp=4, test_batch_size=32, use_dwa=True, yita=0.6)
2024-01-24 13:39:44: *******Train Epoch 1: averaged Loss : 12.416559
2024-01-24 13:39:44: *******Val Epoch 1: averaged Loss : 9.916551
2024-01-24 13:39:44: **************Current best model saved to D:\omer\ST-SSL\experiments\NYCBike1\20240124-133942\best_model.pth
2024-01-24 13:39:45: Traceback (most recent call last):
  File "main.py", line 59, in model_supervisor
    results = trainer.train() # best_eval_loss, best_epoch
  File "D:\omer\ST-SSL\model\trainer.py", line 109, in train
    train_epoch_loss, loss_t = self.train_epoch(epoch, loss_weights)
  File "D:\omer\ST-SSL\model\trainer.py", line 60, in train_epoch
    loss.backward()
  File "C:\Users\IST\.conda\envs\ST-SSL\lib\site-packages\torch\_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "C:\Users\IST\.conda\envs\ST-SSL\lib\site-packages\torch\autograd\__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt

